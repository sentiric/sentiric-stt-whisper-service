# ğŸ§ Sentiric STT Whisper Service (v2.2.0)

[![CI - Build and Push Docker Image](https://github.com/sentiric/sentiric-stt-whisper-service/actions/workflows/build-and-push.yml/badge.svg)](https://github.com/sentiric/sentiric-stt-whisper-service/actions/workflows/build-and-push.yml)

**Sentiric STT**, OpenAI Whisper modelini kullanan, **C++ tabanlÄ±**, GPU hÄ±zlandÄ±rmalÄ±, akÄ±llÄ± kaynak yÃ¶netimine sahip, yÃ¼ksek performanslÄ± bir konuÅŸmadan yazÄ±ya (Speech-to-Text) mikroservisidir.

## ğŸš€ Ã–zellikler (v2.2.0)

*   **âš¡ Native Performans:** Python baÄŸÄ±mlÄ±lÄ±ÄŸÄ± yok. `whisper.cpp` v1.8.2 motoru ile ultra dÃ¼ÅŸÃ¼k gecikme ve bellek kullanÄ±mÄ±.
*   **ğŸ§  Hibrit Mimari:** 
    *   **VAD (Sessizlik Tespiti):** CPU Ã¼zerinde Ã§alÄ±ÅŸÄ±r (Silero VAD v5). Kaynak tasarrufu saÄŸlar.
    *   **Inference (Transkripsiyon):** GPU (NVIDIA CUDA) Ã¼zerinde Ã§alÄ±ÅŸÄ±r. `Flash Attention` aktiftir.
*   **ğŸ”„ Dynamic Batching:** AynÄ± anda gelen birden fazla isteÄŸi (Parallel Requests) GPU Ã¼zerinde paralel iÅŸler.
*   **ğŸ—£ï¸ Speaker Diarization:** KonuÅŸmacÄ± deÄŸiÅŸimlerini tespit eder (Experimental).
*   **ğŸ“ Context Prompting:** HalÃ¼sinasyonlarÄ± Ã¶nlemek veya terim Ã¶ÄŸretmek iÃ§in modele ipucu (prompt) verilebilir.
*   **ğŸ“¦ Auto-Provisioning:** Model dosyalarÄ±nÄ± (Whisper & VAD) baÅŸlangÄ±Ã§ta otomatik indirir. Manuel iÅŸlem gerektirmez.
*   **ğŸ›ï¸ Omni-Studio:** Entegre Web UI ile tarayÄ±cÄ± Ã¼zerinden test, VAD ayarÄ± ve gÃ¶rselleÅŸtirme.

---

## ğŸ› ï¸ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Ã–n Gereksinimler
*   Docker & Docker Compose
*   (Opsiyonel) NVIDIA GPU & Container Toolkit

### 1. Ã‡alÄ±ÅŸtÄ±rma (GPU)
```bash
make up-gpu
```
*Servis ilk aÃ§Ä±lÄ±ÅŸta gerekli modelleri (~1.5GB) otomatik indirecektir. LoglarÄ± izleyin.*

### 2. Test Etme (Omni-Studio)
TarayÄ±cÄ±nÄ±zda **`http://localhost:15030`** adresine gidin.
*   Mikrofon ile kayÄ±t yapÄ±n.
*   Dosya yÃ¼kleyin.
*   Prompt (Ä°pucu) girerek sonucu yÃ¶nlendirin.

### 3. API KullanÄ±mÄ±
```bash
curl http://localhost:15030/v1/transcribe \
  -F "file=@audio.wav" \
  -F "language=tr" \
  -F "prompt=AltyazÄ± ekleme."
```

---

## âš™ï¸ YapÄ±landÄ±rma (Docker Compose)

Ana ayarlar `docker-compose.yml` Ã¼zerinden yÃ¶netilir:

| DeÄŸiÅŸken | VarsayÄ±lan | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `STT_WHISPER_SERVICE_MODEL_FILENAME` | `ggml-medium.bin` | KullanÄ±lacak Whisper modeli (tiny, base, small, medium, large-v3). |
| `STT_WHISPER_SERVICE_PARALLEL_REQUESTS` | `2` | GPU'da aynÄ± anda iÅŸlenecek istek sayÄ±sÄ±. VRAM'e gÃ¶re artÄ±rÄ±n. |
| `STT_WHISPER_SERVICE_ENABLE_VAD` | `true` | Silero VAD aktif/pasif. |
| `STT_WHISPER_SERVICE_ENABLE_DIARIZATION`| `true` | KonuÅŸmacÄ± ayrÄ±ÅŸtÄ±rma aktif/pasif. |
| `STT_WHISPER_SERVICE_FLASH_ATTN` | `true` | GPU Flash Attention optimizasyonu. |

---

## ğŸ—ï¸ Mimari

```mermaid
graph TD
    Client[Client / Gateway] -->|HTTP/gRPC| API[API Layer]
    API -->|Audio| Resampler[Resampler (16kHz)]
    Resampler -->|Float32| VAD[Silero VAD (CPU)]
    
    VAD -- Silence --> Discard[Discard]
    VAD -- Speech --> Queue[State Pool Queue]
    
    Queue -->|Batch| GPU[Whisper Engine (CUDA)]
    GPU -->|Tokens| Decoder[Decoder & Diarization]
    Decoder -->|JSON| Client
```

## ğŸ“œ Lisans
AGPLv3 License. `whisper.cpp` ve `ggml` kÃ¼tÃ¼phanelerine dayanÄ±r.

